# ===== EMBEDDING CONFIGURATION =====
# Choose embedding method: huggingface (free, recommended), voyage, openai, or fastembed
EMBEDDING_METHOD=huggingface
HF_TOKEN=your_huggingface_token_here
HF_EMBEDDING_MODEL=BAAI/bge-base-en-v1.5

# Optional: Alternative embedding backends
OPENAI_API_KEY=your_openai_api_key_here
VOYAGE_API_KEY=your_voyage_api_key_here

# ===== OLLAMA (Local LLM) CONFIGURATION =====
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=smollm2:360m
OLLAMA_MODEL_CLOUD=gpt-oss:20b-cloud
OLLAMA_API_KEY=your_ollama_api_key_here

# ===== DOCUMENT CONFIGURATION =====
# For Docker deployment, documents are uploaded via Gradio UI
# Optional: Default document path (used if no upload provided)
SAMPLE_DOCUMENT_PATH=~/Documents/Books/Atomic_Habits_James_Clear.pdf
SAVE_DIR=./rag_data

# ===== CHUNKING CONFIGURATION =====
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K=5

# ===== TOKEN LIMITS FOR LLM =====
TOKEN_LIMIT_BASE=512
TOKEN_LIMIT_PER_SOURCE=200
TOKEN_LIMIT_MAX=2048

# ===== GRADIO UI CONFIGURATION =====
GRADIO_SERVER_NAME=0.0.0.0
GRADIO_SERVER_PORT=7860
GRADIO_SHARE=false
